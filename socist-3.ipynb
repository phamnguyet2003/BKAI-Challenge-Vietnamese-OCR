{"metadata":{"colab":{"name":"Copy of Vietnamese_Handwritten_Hackathon_CRNN_Solution.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"accelerator":"GPU","language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Vietnamese Handwritten Recognition with CRNN model","metadata":{"id":"ImHu0JlkvPQe"}},{"cell_type":"markdown","source":"## Data Loader","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom torchvision.transforms import ToTensor, Resize, Compose\nimport torchvision.transforms.functional as F\nimport os\nimport numpy as np\nfrom PIL import Image\n\n\ntrain_folder_path = '/kaggle/input/handwritten-ocr/training_data/new_train' \ntest_folder_path = '/kaggle/input/handwritten-ocr/public_test_data/new_public_test'\nlabel_file_path = '/kaggle/input/handwriting/train_gt.txt'\nroot = '/kaggle/input/handwritten-ocr'\n\n\ndef encode_to_num(text, char_list):\n    encoded_label = []\n    for char in text:\n        encoded_label.append(char_list.index(char)+1)\n    return encoded_label\n\nclass OCRDataset(Dataset):\n    def __init__(self, root, train=True, transform=None):\n        self.train = train\n        self.transform = transform\n        if train:\n            dir = os.path.join(root, train_folder_path)\n            paths = os.listdir(dir)\n            image_files = [os.path.join(dir, path) for path in paths]\n            label_file = label_file_path\n        else:\n            dir = os.path.join(root, test_folder_path)\n            paths = os.listdir(dir)\n            image_files = [os.path.join(dir, path) for path in paths]\n        \n        self.images_path = image_files\n        if train:\n            self.labels = []\n            with open(label_file, encoding='utf-8') as f:\n                self.labels = [line.split()[1] for line in f.readlines()]\n            char_list= set()\n            for label in self.labels:\n                char_list.update(set(label))\n            self.char_list = sorted(char_list)\n            for i in range(len(self.labels)):\n                self.labels[i] = encode_to_num(self.labels[i], self.char_list)\n\n    def __len__(self):\n        return len(self.images_path)\n    def __getitem__(self, idx):      \n        image_path = self.images_path[idx]\n        image = Image.open(image_path).convert('L')\n        if self.transform:\n            image = self.transform(image)\n        if self.train:\n            label = self.labels[idx]\n            max_seq_len = 32\n            padded_label = np.squeeze(pad_sequences([label], maxlen=max_seq_len, padding='post', value = 0))\n            return image, padded_label, len(label)\n        else:\n            return image\n        \n\n\ntransform = Compose([\n    Resize((64,128)),\n    ToTensor(),\n    ])\n\ntrain_dataloader = DataLoader(\n    dataset=OCRDataset(root = train_folder_path, train=True, transform=transform),\n    batch_size=8,\n    num_workers=4,\n    drop_last=True,\n    shuffle=True\n)\ntest_dataloader = DataLoader(\n    dataset=OCRDataset(root = test_folder_path, train=False, transform=transform),\n    batch_size=8,\n    num_workers=4,\n    drop_last=True,\n    shuffle=True\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-15T09:40:15.671651Z","iopub.execute_input":"2023-09-15T09:40:15.672176Z","iopub.status.idle":"2023-09-15T09:40:17.162594Z","shell.execute_reply.started":"2023-09-15T09:40:15.672133Z","shell.execute_reply":"2023-09-15T09:40:17.161456Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"\n# if __name__ == '__main__':\nocr = OCRDataset(root = root, train=True, transform=transform)\nimage, label,_ = ocr.__getitem__(100)\nprint(image.shape)\nprint(label)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-15T09:40:17.165546Z","iopub.execute_input":"2023-09-15T09:40:17.166438Z","iopub.status.idle":"2023-09-15T09:40:18.448984Z","shell.execute_reply.started":"2023-09-15T09:40:17.166396Z","shell.execute_reply":"2023-09-15T09:40:18.447946Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"torch.Size([1, 64, 128])\n[ 51 131   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n","output_type":"stream"}]},{"cell_type":"code","source":"\n    for images, labels, nothing in train_dataloader:\n        print(images)\n        print(labels)\n        print(nothing)\n        break","metadata":{"execution":{"iopub.status.busy":"2023-09-15T09:40:18.450546Z","iopub.execute_input":"2023-09-15T09:40:18.450900Z","iopub.status.idle":"2023-09-15T09:40:18.971575Z","shell.execute_reply.started":"2023-09-15T09:40:18.450866Z","shell.execute_reply":"2023-09-15T09:40:18.969403Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"tensor([[[[0.6667, 0.6667, 0.6627,  ..., 0.6627, 0.6627, 0.6627],\n          [0.6627, 0.6627, 0.6588,  ..., 0.6667, 0.6667, 0.6667],\n          [0.6627, 0.6627, 0.6588,  ..., 0.6627, 0.6667, 0.6627],\n          ...,\n          [0.6784, 0.6627, 0.6510,  ..., 0.6431, 0.6471, 0.6510],\n          [0.6784, 0.6667, 0.6549,  ..., 0.6431, 0.6471, 0.6510],\n          [0.6784, 0.6706, 0.6588,  ..., 0.6392, 0.6431, 0.6471]]],\n\n\n        [[[0.9294, 0.9294, 0.9255,  ..., 0.9059, 0.8941, 0.8902],\n          [0.9255, 0.9294, 0.9294,  ..., 0.9137, 0.8980, 0.8863],\n          [0.9216, 0.9176, 0.9294,  ..., 0.9098, 0.8941, 0.8863],\n          ...,\n          [0.8627, 0.8863, 0.9020,  ..., 0.9216, 0.9176, 0.9137],\n          [0.8549, 0.8745, 0.9098,  ..., 0.9137, 0.9216, 0.9137],\n          [0.8706, 0.8824, 0.9059,  ..., 0.9137, 0.9216, 0.9294]]],\n\n\n        [[[0.6157, 0.6118, 0.6078,  ..., 0.6157, 0.6118, 0.6118],\n          [0.6157, 0.6196, 0.6275,  ..., 0.6157, 0.6118, 0.6118],\n          [0.6235, 0.6235, 0.6196,  ..., 0.6157, 0.6196, 0.6196],\n          ...,\n          [0.6353, 0.6353, 0.6392,  ..., 0.6353, 0.6353, 0.6353],\n          [0.6353, 0.6392, 0.6431,  ..., 0.6353, 0.6353, 0.6353],\n          [0.6314, 0.6353, 0.6392,  ..., 0.6314, 0.6314, 0.6314]]],\n\n\n        ...,\n\n\n        [[[0.5373, 0.5333, 0.5373,  ..., 0.5529, 0.5529, 0.5529],\n          [0.5490, 0.5412, 0.5490,  ..., 0.5529, 0.5608, 0.5608],\n          [0.5490, 0.5490, 0.5529,  ..., 0.5569, 0.5647, 0.5686],\n          ...,\n          [0.5529, 0.5569, 0.5451,  ..., 0.5725, 0.5765, 0.5686],\n          [0.5529, 0.5569, 0.5569,  ..., 0.5686, 0.5608, 0.5608],\n          [0.5569, 0.5529, 0.5529,  ..., 0.5647, 0.5529, 0.5529]]],\n\n\n        [[[0.6824, 0.6824, 0.6824,  ..., 0.6863, 0.6824, 0.6824],\n          [0.6588, 0.6392, 0.6118,  ..., 0.6902, 0.6863, 0.6863],\n          [0.6275, 0.5804, 0.5176,  ..., 0.6902, 0.6902, 0.6902],\n          ...,\n          [0.6824, 0.6824, 0.6784,  ..., 0.6784, 0.6745, 0.6745],\n          [0.6784, 0.6824, 0.6784,  ..., 0.6784, 0.6745, 0.6745],\n          [0.6745, 0.6784, 0.6824,  ..., 0.6784, 0.6784, 0.6784]]],\n\n\n        [[[0.6196, 0.6000, 0.6039,  ..., 0.5098, 0.5294, 0.5373],\n          [0.6235, 0.6118, 0.6235,  ..., 0.5216, 0.5373, 0.5294],\n          [0.6196, 0.6157, 0.6235,  ..., 0.5216, 0.5333, 0.5333],\n          ...,\n          [0.6157, 0.6196, 0.6196,  ..., 0.5137, 0.5059, 0.5059],\n          [0.6196, 0.6118, 0.6078,  ..., 0.5216, 0.5059, 0.5216],\n          [0.6157, 0.6118, 0.5922,  ..., 0.5294, 0.5216, 0.5137]]]])\ntensor([[  3, 113,  43,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0],\n        [  2,  14,  10,   2,  15,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0],\n        [ 20,  36,  41,  35,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0],\n        [ 40,  32,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0],\n        [ 47,  45,  73,  36,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0],\n        [ 88,  16,  98,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0],\n        [ 21,  45,  70,  40,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0],\n        [  8,  42,  42,  41,  34,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           0,   0,   0,   0]], dtype=torch.int32)\ntensor([3, 5, 4, 2, 4, 4, 4, 5])\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train_dataloader.__len__()*8)\nprint(test_dataloader.__len__()*8)","metadata":{"execution":{"iopub.status.busy":"2023-09-15T09:40:18.975062Z","iopub.execute_input":"2023-09-15T09:40:18.975432Z","iopub.status.idle":"2023-09-15T09:40:18.981817Z","shell.execute_reply.started":"2023-09-15T09:40:18.975402Z","shell.execute_reply":"2023-09-15T09:40:18.980549Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"103000\n33000\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Build Model","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n# from torchsummary import summary\n\nclass CRNN(nn.Module):\n    def __init__(self, time_steps, num_classes, drop_out_rate = 0.35):\n        super().__init__()\n        self.time_steps = time_steps\n        #CNN\n        self.conv1 = nn.Sequential(\n        nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding='same', bias=True),\n        nn.BatchNorm2d(num_features=64),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2, stride=(2,2))\n        )\n        self.conv2 = nn.Sequential(\n        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding='same', bias=True),\n        nn.BatchNorm2d(num_features=128),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2, stride=(2,2))\n        )\n        self.conv3 = nn.Sequential(\n        nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding='same', bias=True),\n        nn.BatchNorm2d(num_features=256),\n        nn.ReLU(),\n        )\n        self.conv4 = nn.Sequential(\n        nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding='same', bias=True),\n        nn.Dropout(drop_out_rate),\n        nn.BatchNorm2d(num_features=256),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=(1,2), stride=(1,2))\n        )\n        self.conv5 = nn.Sequential(\n        nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding='same', bias=True),\n        nn.BatchNorm2d(num_features=512),\n        nn.ReLU(),\n        )\n        self.conv6 = nn.Sequential(\n        nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding='same', bias=True),\n        nn.Dropout(drop_out_rate),\n        nn.BatchNorm2d(num_features=512),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=(1,2), stride=(1,2))     \n        )   \n        self.conv7 = nn.Sequential(\n        nn.Conv2d(in_channels=512, out_channels=512, kernel_size=2, padding='same', bias=True),\n        nn.Dropout(0.25),\n        nn.BatchNorm2d(num_features=512),\n        nn.ReLU()\n        )\n\n        self.fc1 = nn.Sequential(\n        nn.Linear(4096, 512),\n        nn.ReLU())\n\n        #RNN\n        self.rnn1 = nn.LSTM(input_size=512, hidden_size=256, bidirectional=True, batch_first=True)\n        self.rnn2 = nn.LSTM(input_size=512, hidden_size=256, bidirectional=True, batch_first=True)\n        #FC\n        self.fc2 = nn.Linear(512, num_classes)\n        #Softmax\n        self.softmax = nn.LogSoftmax(dim=2)\n\n    def forward(self,x):\n        x = self.conv1(x)\n        x = self.conv2(x)        \n        x = self.conv3(x)\n        x = self.conv4(x)\n        x = self.conv5(x)\n        x = self.conv6(x)\n        x = self.conv7(x)\n        \n        #CNN to RNN\n        x = x.reshape(x.shape[0], self.time_steps, -1)  # reshape (batch_size, seq_length, -1) # 16 = time_steps\n        x = self.fc1(x)\n       \n        x = self.rnn1(x)[0]\n        x = self.rnn2(x)[0]\n        x = self.fc2(x)\n        x = self.softmax(x)\n        x = x.permute(1,0,2)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-09-15T09:40:18.983625Z","iopub.execute_input":"2023-09-15T09:40:18.984427Z","iopub.status.idle":"2023-09-15T09:40:19.004852Z","shell.execute_reply.started":"2023-09-15T09:40:18.984392Z","shell.execute_reply":"2023-09-15T09:40:19.003891Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_data = torch.rand(8, 1, 64, 128)\n\nmodel = CRNN(time_steps = 16,num_classes=188).cuda()\nif torch.cuda.is_available():\n    input_data = input_data.cuda()\nwhile True:\n    result = model(input_data)\n    print(result.shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2023-09-15T09:40:19.006242Z","iopub.execute_input":"2023-09-15T09:40:19.007186Z","iopub.status.idle":"2023-09-15T09:40:19.356776Z","shell.execute_reply.started":"2023-09-15T09:40:19.007136Z","shell.execute_reply":"2023-09-15T09:40:19.353766Z"},"trusted":true},"execution_count":22,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m input_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m128\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mCRNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m188\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m      5\u001b[0m     input_data \u001b[38;5;241m=\u001b[39m input_data\u001b[38;5;241m.\u001b[39mcuda()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:905\u001b[0m, in \u001b[0;36mModule.cuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    889\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    890\u001b[0m \n\u001b[1;32m    891\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 905\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:905\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    889\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    890\u001b[0m \n\u001b[1;32m    891\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 905\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.76 GiB total capacity; 140.29 MiB already allocated; 5.75 MiB free; 144.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.76 GiB total capacity; 140.29 MiB already allocated; 5.75 MiB free; 144.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","output_type":"error"}]},{"cell_type":"markdown","source":"## Train model","metadata":{}},{"cell_type":"code","source":"!pip install mltu","metadata":{"execution":{"iopub.status.busy":"2023-09-15T09:40:19.358017Z","iopub.status.idle":"2023-09-15T09:40:19.358618Z","shell.execute_reply.started":"2023-09-15T09:40:19.358358Z","shell.execute_reply":"2023-09-15T09:40:19.358383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom datetime import datetime\n\nfrom mltu.configs import BaseModelConfigs\n\nclass ModelConfigs(BaseModelConfigs):\n    def __init__(self):\n        super().__init__()\n        self.trained_models = 'trained_model'\n        self.root = 'data'\n        self.height = 64\n        self.width = 128\n        self.max_label_len = 16\n        self.epochs = 100        \n        self.batch_size = 8\n        self.learning_rate = 1e-3\n        self.train_workers = 4\n        self.logging = 'tensorboard'\n        self.checkpoint = None","metadata":{"execution":{"iopub.status.busy":"2023-09-15T09:40:19.360753Z","iopub.status.idle":"2023-09-15T09:40:19.361236Z","shell.execute_reply.started":"2023-09-15T09:40:19.360986Z","shell.execute_reply":"2023-09-15T09:40:19.361021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pip install torchtools\n","metadata":{"execution":{"iopub.status.busy":"2023-09-15T09:40:19.364921Z","iopub.status.idle":"2023-09-15T09:40:19.365480Z","shell.execute_reply.started":"2023-09-15T09:40:19.365186Z","shell.execute_reply":"2023-09-15T09:40:19.365211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def validation(model, device, valid_loader, loss_function):\n    model.eval()\n    for iter, (images, padded_labels, label_lenghts) in enumerate(val_dataloader):\n            images = images.to(device)\n            padded_labels = padded_labels.to(device)\n            with torch.no_grad():\n                predictions = model(images)  \n                loss_value = criterion(predictions, padded_labels, output_lengths, label_lenghts)\n    writer.add_scalar(\"Val/Loss\", loss_value, epoch)\n    checkpoint = {\n        \"epoch\": epoch + 1,\n        \"best_loss\" : best_loss,\n        \"model\": model.state_dict(),\n        \"optimizer\": optimizer.state_dict()\n    }\n    torch.save(checkpoint, \"{}/last_crnn.pt\".format(trained_models))\n\n    if loss_value >= best_loss:\n        torch.save(checkpoint, \"{}/best_crnn.pt\".format(trained_models))\n        best_loss = loss_value\n    print('Validate', loss_value)\n","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2023-09-15T09:40:19.367285Z","iopub.status.idle":"2023-09-15T09:40:19.367841Z","shell.execute_reply.started":"2023-09-15T09:40:19.367563Z","shell.execute_reply":"2023-09-15T09:40:19.367586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install tensorboard","metadata":{"execution":{"iopub.status.busy":"2023-09-15T09:40:19.369568Z","iopub.status.idle":"2023-09-15T09:40:19.370063Z","shell.execute_reply.started":"2023-09-15T09:40:19.369806Z","shell.execute_reply":"2023-09-15T09:40:19.369828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import torch\n# import torch.nn as nn\n# import torch.optim as optim\n# import torch.utils.data as data\n# from torchvision import datasets, transforms\n# import os\n# import torch\n# import torch.nn as nn\n# # from OCRDataset import OCRDataset\n# from torchvision.transforms import ToTensor, Resize, Compose, RandomAffine, ColorJitter\n# from torchvision.transforms import ToTensor, Resize, Compose\n# from torch.utils.data import DataLoader\n# from torch.utils.data import random_split\n# # from model import CRNN\n# import itertools\n# import numpy as np\n# from argparse import ArgumentParser\n# # from config import ModelConfigs\n# from tqdm.autonotebook import tqdm\n# from torch.utils.tensorboard import SummaryWriter\n# import shutil\n# import warnings\n# warnings.simplefilter(\"ignore\")\n\n# # augment data\n# augment_transform= Compose([RandomAffine(\n#                                             degrees=(-5, 5),\n#                                             scale=(0.5, 1.05), \n#                                             shear=10),\n#                                             ColorJitter(\n#                                                         brightness=0.5, \n#                                                         contrast=0.5,\n#                                                         saturation=0.5,\n#                                                         hue=0.5)\n#                            ])\n\n# def validation(model, device, val_dataloader, loss_function):\n#     model.eval()\n#     loss_value = 0\n#     for iter, (images, padded_labels, label_lenghts) in enumerate(val_dataloader):\n#         images = images.to(device)\n#         padded_labels = padded_labels.to(device)\n#         with torch.no_grad():\n#             predictions = model(images)  \n#             loss_value = criterion(predictions, padded_labels, output_lengths, label_lenghts)\n#     writer.add_scalar(\"Val/Loss\", loss_value, epoch)\n#     checkpoint = {\n#         \"epoch\": epoch + 1,\n#         \"best_loss\" : best_loss,\n#         \"model\": model.state_dict(),\n#         \"optimizer\": optimizer.state_dict()\n#     }\n#     torch.save(checkpoint, \"{}/last_crnn.pt\".format(trained_models))\n\n#     if loss_value >= best_loss:\n#         torch.save(checkpoint, \"{}/best_crnn.pt\".format(trained_models))\n#         best_loss = loss_value\n#     return loss_value\n\n# def traindata(device, model, start_epoch, epochs, optimizer, loss_function , train_loader, valid_loader):\n#     # Early stopping\n#     last_loss = 100\n#     patience = 2\n#     triggertimes = 0\n    \n#     for epoch in range(start_epoch, epochs):\n#         model.train()\n#         progress_bar = tqdm(train_loader, colour=\"green\")\n#         for iter, (images, padded_labels, label_lenghts) in enumerate(train_loader):\n#             images = augment_transform(images)\n#             images = images.to(device)\n#             padded_labels = padded_labels.to(device)\n#             #forward\n#             outputs = model(images)\n#             loss_value = loss_function(outputs, padded_labels, output_lengths, label_lenghts)\n#             if torch.isinf(loss_value):\n#                 print(outputs)\n#                 exit()\n#             progress_bar.set_description(\"Epoch {}/{}. Iteration {}/{}. Loss{:3f}\".format(epoch+1, num_epochs, iter+1, num_iters, loss_value))\n#             writer.add_scalar(\"Train/Loss\", loss_value, epoch*num_iters+iter)\n#             #backward\n#             optimizer.zero_grad()\n#             loss_value.backward()  \n#             optimizer.step()\n\n\n#             # Show progress\n#             if iter % 100 == 0 or iter == len(train_loader):\n#                 print('[{}/{}, {}/{}] loss: {:.8}'.format(epoch, epochs, iter, len(train_loader), loss_value.item()))\n\n#         # Early stopping\n#         current_loss = validation(model, device, valid_loader, loss_function)\n#         print('The Current Loss:', current_loss)\n\n#         if current_loss > last_loss:\n#             trigger_times += 1\n#             print('Trigger Times:', trigger_times)\n\n#             if trigger_times >= patience:\n#                 print('Early stopping!\\nStart to test process.')\n#                 return model\n\n#         else:\n#             print('trigger times: 0')\n#             trigger_times = 0\n\n#         last_loss = current_loss\n\n#     return model\n\n\n# def words_from_labels(labels, char_list):\n#     \"\"\"\n#     converts the list of encoded integer labels to word strings like eg. [12,10,29] returns CAT \n#     \"\"\"\n#     txt=[]\n#     for ele in labels:\n#         if ele == 0: # CTC blank space\n#             txt.append(\"\")\n#         else:\n#             #print(letters[ele])\n#             txt.append(char_list[ele+1])\n#     return \"\".join(txt)\n\n# def decode_batch(test_func, word_batch): #take only a sequence once a time\n#     \"\"\"\n#     Takes the Batch of Predictions and decodes the Predictions by Best Path Decoding and Returns the Output\n#     \"\"\"\n#     out = test_func([word_batch])[0] #returns the predicted output matrix of the model\n#     ret = []\n#     for j in range(out.shape[0]):\n#         out_best = list(np.argmax(out[j, :], 1))\n#         out_best = [k for k, g in itertools.groupby(out_best)]\n#         outstr = words_from_labels(out_best)\n#         ret.append(outstr)\n#     return ret\n\n# # device\n# if torch.cuda.is_available():\n#         device = torch.device(\"cuda\")\n# else:\n#     device = torch.device(\"cpu\")\n\n\n# configs = ModelConfigs()\n# root = configs.root\n# num_epochs = configs.epochs\n# batch_size = configs.batch_size\n# max_label_len = configs.max_label_len\n# height = configs.height\n# width = configs.width\n# learning_rate = configs.learning_rate\n# logging = configs.logging\n# trained_models = configs.trained_models\n# checkpoint = configs.checkpoint\n\n# transform = Compose([\n#         Resize((height,width)),\n#         ToTensor(),\n#          ])\n\n# #split train/val dataset\n# dataset = OCRDataset(root = train_folder_path, train=True, transform=transform)  # Replace with your dataset\n# train_size = int(0.9 * len(dataset))\n# val_size = len(dataset) - train_size\n# train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\n# train_dataloader = DataLoader(\n#     dataset=train_dataset,\n#     batch_size=batch_size,\n#     num_workers=4,\n#     drop_last=True,\n#     shuffle=True\n# )\n\n# val_dataloader = DataLoader(\n#     dataset=val_dataset,\n#     batch_size=batch_size,\n#     num_workers=4,\n#     drop_last=True,\n#     shuffle=True\n# )\n# # if not os.path.isdir(logging):\n# #     shutil.rmtree(logging)\n# # if not os.path.isdir(trained_models):\n# #     os.mkdir(trained_models)\n# writer = SummaryWriter(logging)\n# # Model architecture\n# # class CRNN(nn.Module):\n\n# char_list = dataset.char_list\n# model = CRNN(time_steps=max_label_len, num_classes=len(char_list)+1).to(device)\n# criterion = nn.CTCLoss(blank=0)\n# output_lengths = torch.full(size=(batch_size,), fill_value=max_label_len, dtype=torch.long)\n# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n# best_loss = 0\n# if checkpoint:\n#     checkpoint = torch.load(checkpoint)\n#     start_epoch = checkpoint['epoch']\n#     best_loss = checkpoint['best_loss']  \n#     model.load_state_dict(checkpoint[\"model\"])\n#     optimizer.load_state_dict(checkpoint[\"optimizer\"])\n# else:\n#     start_epoch = 0  \n# num_iters = len(train_dataloader)\n\n# traindata(device, model, start_epoch, num_epochs, optimizer, criterion , train_dataloader, val_dataloader)\n\n# validation(model, device, val_dataloader, criterion)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-15T09:40:19.371792Z","iopub.status.idle":"2023-09-15T09:40:19.372318Z","shell.execute_reply.started":"2023-09-15T09:40:19.372060Z","shell.execute_reply":"2023-09-15T09:40:19.372095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Add callbacks","metadata":{}},{"cell_type":"markdown","source":"## Save point","metadata":{}},{"cell_type":"code","source":"import torch\n\ndef save_checkpoint(model, optimizer, epoch, val_loss, checkpoint_path='checkpoint.pth'):\n    checkpoint = {\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'val_loss': val_loss,\n    }\n    torch.save(checkpoint, checkpoint_path)\n\n# Usage during training loop:\n# After evaluating validation loss\n# save_checkpoint(model, optimizer, epoch, val_loss, 'checkpoint.pth')","metadata":{"execution":{"iopub.status.busy":"2023-09-15T09:40:19.373831Z","iopub.status.idle":"2023-09-15T09:40:19.374771Z","shell.execute_reply.started":"2023-09-15T09:40:19.374517Z","shell.execute_reply":"2023-09-15T09:40:19.374545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Early Stopping","metadata":{}},{"cell_type":"code","source":"class EarlyStopping:\n    def __init__(self, patience=20, min_delta=1e-8, restore_best_weights=True):\n        self.patience = patience\n        self.min_delta = min_delta\n        self.restore_best_weights = restore_best_weights\n        self.counter = 0\n        self.best_loss = None\n        self.early_stop = False\n\n    def __call__(self, val_loss):\n        if self.best_loss is None:\n            self.best_loss = val_loss\n        elif val_loss < self.best_loss - self.min_delta:\n            self.best_loss = val_loss\n            self.counter = 0\n        else:\n            self.counter += 1\n            if self.counter >= self.patience:\n                self.early_stop = True\n\n# # Usage during training loop:\n# early_stopping = EarlyStopping(patience=20, min_delta=1e-8, restore_best_weights=True)\n# if early_stopping(val_loss):\n#     print(\"Early stopping triggered.\")\n#     if early_stopping.restore_best_weights:\n#         # Restore the model to the best state\n#         checkpoint = torch.load('checkpoint.pth')\n#         model.load_state_dict(checkpoint['model_state_dict'])\n#         optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","metadata":{"execution":{"iopub.status.busy":"2023-09-15T09:40:19.376277Z","iopub.status.idle":"2023-09-15T09:40:19.377278Z","shell.execute_reply.started":"2023-09-15T09:40:19.377011Z","shell.execute_reply":"2023-09-15T09:40:19.377041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ReduceLR","metadata":{}},{"cell_type":"code","source":"\n# # Create a learning rate scheduler\n# scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=10, verbose=True)\n\n# # Usage during training loop:\n# scheduler.step(val_loss)  # Adjust learning rate based on validation loss\n","metadata":{"execution":{"iopub.status.busy":"2023-09-15T09:40:19.378793Z","iopub.status.idle":"2023-09-15T09:40:19.379752Z","shell.execute_reply.started":"2023-09-15T09:40:19.379485Z","shell.execute_reply":"2023-09-15T09:40:19.379512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nfrom torchvision.transforms import ToTensor, Resize, Compose, RandomAffine, ColorJitter\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import random_split\nimport itertools\nimport numpy as np\nfrom argparse import ArgumentParser\nfrom tqdm.autonotebook import tqdm\nfrom torch.utils.tensorboard import SummaryWriter\nimport shutil\nimport warnings\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\nwarnings.simplefilter(\"ignore\")\n\ndef words_from_labels(labels, char_list):\n    \"\"\"\n    converts the list of encoded integer labels to word strings like eg. [12,10,29] returns CAT \n    \"\"\"\n    txt = []\n    for ele in labels:\n        if ele == 0:  # CTC blank space\n            txt.append(\"\")\n        else:\n            txt.append(char_list[ele + 1])\n    return \"\".join(txt)\n\ndef decode_batch(test_func, word_batch):\n    \"\"\"\n    Takes the Batch of Predictions and decodes the Predictions by Best Path Decoding and Returns the Output\n    \"\"\"\n    out = test_func([word_batch])[0]\n    ret = []\n    for j in range(out.shape[0]):\n        out_best = list(np.argmax(out[j, :], 1))\n        out_best = [k for k, g in itertools.groupby(out_best)]\n        outstr = words_from_labels(out_best)\n        ret.append(outstr)\n    return ret\n\nif __name__ == '__main__':\n    if torch.cuda.is_available():\n        device = torch.device(\"cuda\")\n    else:\n        device = torch.device(\"cpu\")\n\n    configs = ModelConfigs()\n    root = configs.root\n#     num_epochs = configs.epochs\n    num_epochs = 1\n\n    batch_size = configs.batch_size\n    max_label_len = configs.max_label_len\n    height = configs.height\n    width = configs.width\n    learning_rate = configs.learning_rate\n    logging = configs.logging\n    trained_models = configs.trained_models\n    checkpoint = configs.checkpoint\n\n    transform = Compose([\n        Resize((height, width)),\n        ToTensor(),\n    ])\n\n    augment_transform = Compose([RandomAffine(\n        degrees=(-5, 5),\n        scale=(0.5, 1.05),\n        shear=10),\n        ColorJitter(\n            brightness=0.5,\n            contrast=0.5,\n            saturation=0.5,\n            hue=0.5)])\n\n    dataset = OCRDataset(root=root, train=True, transform=transform)\n    train_size = int(0.9 * len(dataset))\n    val_size = len(dataset) - train_size\n    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\n    train_dataloader = DataLoader(\n        dataset=train_dataset,\n        batch_size=batch_size,\n        num_workers=4,\n        drop_last=True,\n        shuffle=True\n    )\n\n    val_dataloader = DataLoader(\n        dataset=val_dataset,\n        batch_size=batch_size,\n        num_workers=4,\n        drop_last=True,\n        shuffle=True\n    )\n\n    if not os.path.isdir(logging):\n        shutil.rmtree(logging)\n    if not os.path.isdir(trained_models):\n        os.mkdir(trained_models)\n    writer = SummaryWriter(logging)\n\n    char_list = dataset.char_list\n    model = CRNN(time_steps=max_label_len, num_classes=len(char_list) + 1).to(device)\n    criterion = nn.CTCLoss(blank=0)\n    output_lengths = torch.full(size=(batch_size,), fill_value=max_label_len, dtype=torch.long)\n    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n    \n    # Initialize ReduceLROnPlateau scheduler\n    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n    # Early stopping \n    early_stopping = EarlyStopping(patience=20, min_delta=1e-8, restore_best_weights=True)\n    \n    best_loss = float('inf')\n    early_stopping_counter = 0\n    early_stopping_patience = 10  # Adjust as needed\n\n    if checkpoint:\n        checkpoint = torch.load(checkpoint)\n        start_epoch = checkpoint['epoch']\n        best_loss = checkpoint['best_loss']\n        model.load_state_dict(checkpoint[\"model\"])\n        optimizer.load_state_dict(checkpoint[\"optimizer\"])\n    else:\n        start_epoch = 0\n    num_iters = len(train_dataloader)\n\n    for epoch in range(start_epoch, num_epochs):\n        model.train()\n        progress_bar = tqdm(train_dataloader, colour=\"green\")\n        for iter, (images, padded_labels, label_lenghts) in enumerate(train_dataloader):\n            images = augment_transform(images)\n            images = images.to(device)\n            padded_labels = padded_labels.to(device)\n            outputs = model(images)\n            loss_value = criterion(outputs, padded_labels, output_lengths, label_lenghts)\n            if torch.isinf(loss_value):\n                print(outputs)\n                exit()\n            progress_bar.set_description(\"Epoch {}/{}. Iteration {}/{}. Loss{:3f}\".format(epoch + 1, num_epochs,\n                                                                                         iter + 1, num_iters, loss_value))\n            writer.add_scalar(\"Train/Loss\", loss_value, epoch * num_iters + iter)\n            optimizer.zero_grad()\n            loss_value.backward()\n            optimizer.step()\n\n        model.eval()\n        for iter, (images, padded_labels, label_lenghts) in enumerate(val_dataloader):\n            images = images.to(device)\n            padded_labels = padded_labels.to(device)\n            with torch.no_grad():\n                predictions = model(images)\n                loss_value = criterion(predictions, padded_labels, output_lengths, label_lenghts)\n        writer.add_scalar(\"Val/Loss\", loss_value, epoch)\n        \n        # Update learning rate scheduler\n        scheduler.step(loss_value)\n        \n        \n        checkpoint = {\n            \"epoch\": epoch + 1,\n            \"best_loss\": best_loss,\n            \"model\": model.state_dict(),\n            \"optimizer\": optimizer.state_dict()\n        }\n#         torch.save(checkpoint, \"{}/last_crnn.pt\".format(trained_models))\n\n#         if loss_value <= best_loss:\n#             torch.save(checkpoint, \"{}/best_crnn.pt\".format(trained_models))\n#             best_loss = loss_value\n#         else:\n#             early_stopping_counter += 1\n#             if early_stopping_counter >= early_stopping_patience:\n#                 print(\"Early stopping triggered.\")\n#                 break\n                \n        if early_stopping(val_loss):\n            print(\"Early stopping triggered.\")\n        if early_stopping.restore_best_weights:\n            checkpoint = torch.load('checkpoint.pth')\n            model.load_state_dict(checkpoint['model_state_dict'])\n            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n            \n        print('Validate', loss_value)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-15T09:40:19.381475Z","iopub.status.idle":"2023-09-15T09:40:19.381940Z","shell.execute_reply.started":"2023-09-15T09:40:19.381704Z","shell.execute_reply":"2023-09-15T09:40:19.381727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = traindata(device, model, start_epoch, num_epochs, optimizer, criterion , train_dataloader, val_dataloader)\n\n# model","metadata":{"execution":{"iopub.status.busy":"2023-09-15T09:40:19.383624Z","iopub.status.idle":"2023-09-15T09:40:19.384111Z","shell.execute_reply.started":"2023-09-15T09:40:19.383853Z","shell.execute_reply":"2023-09-15T09:40:19.383875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# validation(model, device, val_dataloader, criterion)\n# ","metadata":{"execution":{"iopub.status.busy":"2023-09-15T09:40:19.387559Z","iopub.status.idle":"2023-09-15T09:40:19.388092Z","shell.execute_reply.started":"2023-09-15T09:40:19.387820Z","shell.execute_reply":"2023-09-15T09:40:19.387844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Exponentially weighted averages are a type of moving average that give more weight and significance to recent data points. This is in contrast to simple moving averages, which give equal weight to all data points within a specified period.","metadata":{"execution":{"iopub.status.busy":"2023-09-15T09:40:19.391557Z","iopub.status.idle":"2023-09-15T09:40:19.392100Z","shell.execute_reply.started":"2023-09-15T09:40:19.391799Z","shell.execute_reply":"2023-09-15T09:40:19.391823Z"},"trusted":true},"execution_count":null,"outputs":[]}]}